{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = \"svg\"\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.autograd import Variable\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import tqdm\n",
    "from itertools import product\n",
    "from math import ceil, log\n",
    "import pennylane as qml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST image dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "path = \"/home/gilbertocunha/Documentos/GitHub/QuantumVariationalCircuits/data/\"\n",
    "X_train = pd.read_csv(path + \"mnist_train.csv\")\n",
    "X_test = pd.read_csv(path + \"mnist_test.csv\")\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get labels from data\n",
    "y_train = X_train[\"label\"].to_numpy()[:6000]\n",
    "y_test = X_test[\"label\"].to_numpy()[:1000]\n",
    "print(y_train.shape, y_test.shape)\n",
    "\n",
    "# Get features from data\n",
    "X_train = X_train.drop(\"label\", axis=1).to_numpy()[:6000]\n",
    "X_test = X_test.drop(\"label\", axis=1).to_numpy()[:1000]\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data is too big, each feature vector has 784 pixels, we need to reduce this heavily. In order to do so, we will utilize truncated Single Valued Decomposition, a dimensionality reduction technique, to reduce our feature vector to 8 values, while maintaining the classes separated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply TSVD\n",
    "tsvd = TruncatedSVD(n_components=16)\n",
    "X_train = tsvd.fit_transform(X_train)\n",
    "X_test = tsvd.fit_transform(X_test)\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, our data needs to be normalized in order to be passed through a quantum circuit. Therefore, we will normalize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize (matrix):\n",
    "    \"\"\"\n",
    "    Normalizes vector squared amplitudes to one\n",
    "    for every vector in the input matrix\n",
    "    \"\"\"\n",
    "    norm = np.sqrt(np.sum(matrix ** 2, -1))\n",
    "    r = []\n",
    "    for i in range(len(matrix)):\n",
    "        r.append(matrix[i,:]/norm[i])\n",
    "    r = np.array(r)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize our data\n",
    "X_train = normalize(X_train)\n",
    "X_test = normalize(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if data is still easily separable after dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting training data\n",
    "dim1, dim2 = 2, 14\n",
    "plt.title(\"Data-points for mnist classes\")\n",
    "for i in range(10):\n",
    "    plt.scatter(X_train[y_train == i][:,dim1], X_train[y_train == i][:,dim2], label=f\"{i}\")\n",
    "plt.xlabel(f\"Dimension {dim1}\")\n",
    "plt.ylabel(f\"Dimension {dim2}\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, features, labels, batch_size):\n",
    "        # Randomly shuffle indices of the data\n",
    "        idx = np.random.permutation(len(features))\n",
    "        \n",
    "        # Split data into batches\n",
    "        self.features = Variable(torch.tensor(self.split(features[idx], batch_size)), requires_grad=False)\n",
    "        self.labels = Variable(torch.tensor(self.split(labels[idx], batch_size)), requires_grad=False)\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.counter = 0\n",
    "        assert len(self.features) == len(self.labels), \"features and labels have different sizes\"\n",
    "        \n",
    "    def split(self, array, batch_size):\n",
    "        r = []\n",
    "        num_splits = len(array)//batch_size\n",
    "        for i in range(num_splits):\n",
    "            start = i*batch_size\n",
    "            size = batch_size\n",
    "            r.append(array[start:start+size])\n",
    "        r = np.stack(r, axis=0)\n",
    "        return r\n",
    "    \n",
    "    def input_size(self):\n",
    "        return len(self.features[0][0])\n",
    "        \n",
    "    def num_qubits(self):\n",
    "        return ceil(log(self.input_size(), 2))\n",
    "        \n",
    "    def sample_batch(self):\n",
    "        \"\"\"\n",
    "        A method that samples a batch from the dataset\n",
    "        \"\"\"\n",
    "        features = self.features[self.counter]\n",
    "        labels = self.labels[self.counter]\n",
    "        self.counter = (self.counter + 1) % len(self.features)\n",
    "        return features, labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, Val, Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into train, test and validation\n",
    "val_split, random_state = 0.2, 42\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=val_split, random_state=random_state)\n",
    "\n",
    "# Creating the datasets for train, test and validation\n",
    "batch_size = 32\n",
    "trainset = Dataset(X_train, y_train, batch_size)\n",
    "valset = Dataset(X_val, y_val, batch_size)\n",
    "testset = Dataset(X_test, y_test, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantum Variational Circuit hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of qubits in the circuit\n",
    "nr_qubits = trainset.num_qubits()\n",
    "\n",
    "# number of layers in the circuit\n",
    "nr_layers = 2\n",
    "\n",
    "# define quantum device\n",
    "dev = qml.device(\"default.qubit\", wires=nr_qubits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantum Variational Circuit Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combinations(values):\n",
    "    \"\"\"\n",
    "    Calculates every possible pair combination of values\n",
    "    \"\"\"\n",
    "    r = []\n",
    "    for i in range(len(values)):\n",
    "        for j in range(i+1,len(values)):\n",
    "            r.append((i,j))\n",
    "    return r\n",
    "\n",
    "# a layer of the circuit ansatz\n",
    "def layer(params, j):\n",
    "    for i in range(params.shape[1]):\n",
    "        qml.RX(params[j, i, 0], wires=i)\n",
    "        qml.RY(params[j, i, 1], wires=i)\n",
    "        qml.RZ(params[j, i, 2], wires=i)\n",
    "\n",
    "    # Add CNOT for every qubit combination\n",
    "    combs = combinations(range(params.shape[1]))\n",
    "    for i, k in combs:\n",
    "        if j % 2 == 1:\n",
    "            i, k = k, i\n",
    "        qml.CNOT(wires=[i, k])\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def qnode(inputs, params):\n",
    "    # Encoding\n",
    "    qml.QubitStateVector(inputs, wires=range(params.shape[1]))\n",
    "    \n",
    "    # repeatedly apply each layer in the circuit\n",
    "    for j in range(params.shape[0]):\n",
    "        layer(params, j)\n",
    "\n",
    "    # returns the expectation of the input matrix A on the first qubit\n",
    "    measurements = [qml.expval(qml.PauliZ(i)) for i in range(params.shape[1])]\n",
    "    return measurements\n",
    "\n",
    "def qvc(params, features):\n",
    "    weights, bias = params\n",
    "    predictions = [circuit(weights, x) + bias for x in features]\n",
    "    return predictions\n",
    "\n",
    "# cost function\n",
    "def loss_fn(predictions, labels):\n",
    "    \"\"\"\n",
    "    A simple square loss function to evaluate predictions\n",
    "    \"\"\"\n",
    "    loss = 0.0\n",
    "    for p, l in zip(predictions, labels):\n",
    "        loss += (l - p) ** 2\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Hybrid Classical-Quantum Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, qnode, nr_layers, nr_qubits):\n",
    "        super(Model, self).__init__()\n",
    "        self.qvc = qml.qnn.TorchLayer(qnode, {\"params\": (nr_layers, nr_qubits, 3)})\n",
    "        self.linear1 = torch.nn.Linear(nr_qubits, 12)\n",
    "        self.linear2 = torch.nn.Linear(12, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.qvc(x)\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "    \n",
    "# Create pytorch model, optimizer and loss function\n",
    "model = Model(qnode, nr_layers, nr_qubits)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.04)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop for the hybrid model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of epochs to train on\n",
    "epochs = 10\n",
    "\n",
    "# Best accuracy and loss\n",
    "best_tr_acc, best_val_acc = 0, 0\n",
    "best_tr_loss, best_val_loss = float(\"inf\"), float(\"inf\")\n",
    "\n",
    "# Performing the training loop\n",
    "epoch_tqdm = tqdm(range(epochs), total=epochs, desc=\"Fitting\")\n",
    "for epoch in epoch_tqdm:\n",
    "    # Iterate training data\n",
    "    tr_accs, tr_losses = [], []\n",
    "    tr_tqdm = tqdm(range(len(trainset)), total=len(trainset), desc=\"Training\")\n",
    "    for _ in tr_tqdm:\n",
    "        # Sample batch of data and get predictions\n",
    "        X, y = trainset.sample_batch()\n",
    "        y_hat = model(X.float())\n",
    "\n",
    "        # Get loss and update parameters\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(y_hat, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Add training info to tqdm progress bar\n",
    "        y_hat = torch.argmax(y_hat.detach(), dim=-1)\n",
    "        tr_acc = accuracy_score(y, y_hat)\n",
    "        info = {\"loss\": loss.item(), \"acc\": tr_acc}\n",
    "        tr_tqdm.set_postfix(info)\n",
    "        tr_accs.append(tr_acc)\n",
    "        tr_losses.append(loss.item())\n",
    "        \n",
    "    # Calculate training epoch accuracy and loss\n",
    "    tr_acc = sum(tr_accs) / len(tr_accs)\n",
    "    tr_loss = sum(tr_losses) / len(tr_losses)\n",
    "    tr_acc = 0.2\n",
    "    tr_loss = 1\n",
    "    \n",
    "    # Get best loss and accuracy\n",
    "    if tr_acc > best_tr_acc: best_tr_acc = tr_acc\n",
    "    if tr_loss < best_tr_loss: best_tr_loss = tr_loss\n",
    "        \n",
    "    # Iterate validation data\n",
    "    val_accs, val_losses = [], []\n",
    "    val_tqdm = tqdm(range(len(valset)), total=len(valset), desc=\"Validating\")\n",
    "    with torch.no_grad():\n",
    "        for _ in val_tqdm:\n",
    "            # Sample batch of data and get predictions\n",
    "            X, y = valset.sample_batch()\n",
    "            y_hat = model(X.float())\n",
    "            loss = loss_fn(y_hat, y)\n",
    "\n",
    "            # Add validation info to tqdm progress bar\n",
    "            y_hat = torch.argmax(y_hat.detach(), dim=-1)\n",
    "            val_acc = accuracy_score(y, y_hat)\n",
    "            info = {\"loss\": loss.item(), \"acc\": val_acc}\n",
    "            val_tqdm.set_postfix(info)\n",
    "            val_accs.append(val_acc)\n",
    "            val_losses.append(loss.item())\n",
    "            \n",
    "    # Calculate training epoch accuracy and loss\n",
    "    val_acc = sum(val_accs) / len(val_accs)\n",
    "    val_loss = sum(val_losses) / len(val_losses)\n",
    "    \n",
    "    # Save best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"models/best_model_dict.pt\")\n",
    "    if val_loss < best_val_loss: best_val_loss = val_loss\n",
    "    \n",
    "    # Update info to tqdm bar\n",
    "    info = {\n",
    "        \"b_tr_acc\": best_tr_acc, \n",
    "        \"b_tr_loss\": best_tr_loss, \n",
    "        \"b_val_acc\": best_val_acc, \n",
    "        \"b_val_loss\": best_val_loss\n",
    "    }\n",
    "    epoch_tqdm.set_postfix(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
