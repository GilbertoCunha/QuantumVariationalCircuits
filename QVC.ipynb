{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.autograd import Variable\n",
    "from tqdm.notebook import tqdm\n",
    "from itertools import product\n",
    "from math import ceil, log\n",
    "import pennylane as qml\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, features, labels, batch_size):\n",
    "        # Randomly shuffle indices of the data\n",
    "        idx = np.random.permutation(len(features))\n",
    "        \n",
    "        # Split data into batches\n",
    "        num_splits = ceil(len(features)/batch_size)\n",
    "        self.features = Variable(torch.tensor(np.split(features[idx], num_splits)), requires_grad=False)\n",
    "        self.labels = Variable(torch.tensor(np.split(labels[idx], num_splits)), requires_grad=False)\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.counter = 0\n",
    "        assert len(self.features) == len(self.labels), \"features and labels have different sizes\"\n",
    "        \n",
    "    def sample_batch(self):\n",
    "        \"\"\"\n",
    "        A method that samples a batch from the dataset\n",
    "        \"\"\"\n",
    "        features = self.features[self.counter]\n",
    "        labels = self.labels[self.counter]\n",
    "        self.counter = (self.counter + 1) % len(self.features)\n",
    "        return features, labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "def normalize (vector):\n",
    "    \"\"\"\n",
    "    Normalizes vector squared amplitudes to one\n",
    "    \"\"\"\n",
    "    norm = np.sqrt(np.sum(vector ** 2, -1))\n",
    "    r = []\n",
    "    for i in range(len(vector)):\n",
    "        r.append(vector[i,:]/norm[i])\n",
    "    r = np.array(r)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define number of datapoints and samples to extract from distribution\n",
    "datapoints, samples = 100000, 64\n",
    "\n",
    "# Generating class 1 data\n",
    "mean, std = -20, 1\n",
    "data1 = normalize(std * np.random.randn(datapoints//2, samples) + mean)\n",
    "labels1 = np.zeros(datapoints//2)\n",
    "\n",
    "# Generating class 2 data\n",
    "mean, std = 5, 3\n",
    "data2 = normalize(std * np.random.randn(datapoints//2, samples) + mean)\n",
    "labels2 = np.ones(datapoints//2)\n",
    "\n",
    "# Concatenating data\n",
    "data = np.concatenate((data1, data2))\n",
    "labels = np.concatenate((labels1, labels2))\n",
    "\n",
    "# Splitting data into train, test and validation\n",
    "test_split, val_split, random_state = 0.2, 0.3, 42\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=test_split, random_state=random_state)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=val_split, random_state=random_state)\n",
    "\n",
    "# Creating the datasets for train, test and validation\n",
    "batch_size = 32\n",
    "trainset = Dataset(X_train, y_train, 32)\n",
    "valset = Dataset(X_val, y_val, 32)\n",
    "testset = Dataset(X_test, y_test, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combinations(values):\n",
    "    \"\"\"\n",
    "    Calculates every possible pair combination of values\n",
    "    \"\"\"\n",
    "    r = []\n",
    "    for i in range(len(values)):\n",
    "        for j in range(i+1,len(values)):\n",
    "            r.append((i,j))\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of qubits in the circuit\n",
    "nr_qubits = ceil(log(samples,2))\n",
    "# number of layers in the circuit\n",
    "nr_layers = 2\n",
    "\n",
    "# randomly initialize parameters from a normal distribution\n",
    "params = np.random.normal(0, np.pi, (nr_layers, nr_qubits, 3))\n",
    "params = Variable(torch.tensor(params), requires_grad=True)\n",
    "\n",
    "# a layer of the circuit ansatz\n",
    "def layer(params, j):\n",
    "    for i in range(params.shape[1]):\n",
    "        qml.RX(params[j, i, 0], wires=i)\n",
    "        qml.RY(params[j, i, 1], wires=i)\n",
    "        qml.RZ(params[j, i, 2], wires=i)\n",
    "\n",
    "    # Add CNOT for every qubit combination\n",
    "    combs = combinations(range(params.shape[1]))\n",
    "    for i, k in combs:\n",
    "        qml.CNOT(wires=[i, k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device(\"default.qubit\", wires=nr_qubits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "@qml.qnode(dev, interface=\"torch\")\n",
    "def circuit(params, x):\n",
    "    # Encoding\n",
    "    qml.QubitStateVector(x, wires=range(params.shape[1]))\n",
    "    # repeatedly apply each layer in the circuit\n",
    "    for j in range(params.shape[0]):\n",
    "        layer(params, j)\n",
    "\n",
    "    # returns the expectation of the input matrix A on the first qubit\n",
    "    return qml.expval(qml.PauliZ(0))\n",
    "\n",
    "def qvc(params, features):\n",
    "    predictions = [circuit(params, x) for x in features]\n",
    "    return predictions\n",
    "\n",
    "# cost function\n",
    "def loss_fn(predictions, labels):\n",
    "    \"\"\"\n",
    "    A simple square loss function to evaluate predictions\n",
    "    \"\"\"\n",
    "    loss = 0.0\n",
    "    for p, l in zip(predictions, labels):\n",
    "        loss += (l - p) ** 2\n",
    "    return loss\n",
    "\n",
    "# set up the optimizer\n",
    "optimizer = torch.optim.Adam([params], lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classes(y_hat):\n",
    "    r = []\n",
    "    for y in y_hat:\n",
    "        if y > 0.5:\n",
    "            r.append(1)\n",
    "        else:\n",
    "            r.append(0)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "246c77dbbda5467fb0a4642260a9b08a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Fitting', max=10.0, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34f49f4ef1354e0a802ecf88c21772a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Training', max=1750.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-493d08d40f0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mRuntimeError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Number of epochs to train on\n",
    "epochs = 10\n",
    "\n",
    "# Performing the training loop\n",
    "epoch_tqdm = tqdm(range(epochs), total=epochs, desc=\"Fitting\")\n",
    "for epoch in epoch_tqdm:\n",
    "    # Iterate training data\n",
    "    tr_accs, tr_losses = [], []\n",
    "    tr_tqdm = tqdm(range(len(trainset)), total=len(trainset), desc=\"Training\")\n",
    "    for _ in tr_tqdm:\n",
    "        # Sample batch of data and get predictions\n",
    "        X, y = trainset.sample_batch()\n",
    "        y_hat = qvc(params, X)\n",
    "\n",
    "        # Get loss and update parameters\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(y_hat, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Add training info to tqdm progress bar\n",
    "        preds = get_classes(y_hat)\n",
    "        tr_acc = accuracy_score(y, preds)\n",
    "        info = {\"loss\": loss.item(), \"acc\": tr_acc}\n",
    "        tr_tqdm.set_postfix(info)\n",
    "        tr_accs.append(tr_acc)\n",
    "        tr_losses.append(loss.item())\n",
    "        \n",
    "    # Calculate training epoch accuracy and loss\n",
    "    tr_acc = sum(tr_accs) / len(tr_accs)\n",
    "    tr_loss = sum(tr_losses) / len(tr_losses)\n",
    "        \n",
    "    # Iterate validation data\n",
    "    val_accs, val_losses = [], []\n",
    "    val_tqdm = tqdm(range(len(trainset)), total=len(trainset), desc=\"Validating\")\n",
    "    with torch.no_grad():\n",
    "        for _ in val_tqdm:\n",
    "            # Sample batch of data and get predictions\n",
    "            X, y = valset.sample_batch()\n",
    "            y_hat = qvc(params, X)\n",
    "            loss = loss_fc(y, y_hat)\n",
    "\n",
    "            # Add validation info to tqdm progress bar\n",
    "            preds = get_classes(y_hat)\n",
    "            val_acc = accuracy_score(y, preds)\n",
    "            info = {\"loss\": loss.item(), \"acc\": val_acc}\n",
    "            val_tqdm.set_postfix(info)\n",
    "            val_accs.append(val_acc)\n",
    "            val_losses.append(loss.item())\n",
    "            \n",
    "    # Calculate training epoch accuracy and loss\n",
    "    val_acc = sum(val_accs) / len(val_accs)\n",
    "    val_loss = sum(val_losses) / len(val_losses)\n",
    "    \n",
    "    # Update info to tqdm bar\n",
    "    info = {\"tr_acc\": tr_acc, \"tr_loss\": tr_loss, \"val_acc\": val_acc, \"val_loss\": val_loss}\n",
    "    epoch_tqdm.set_postfix(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
